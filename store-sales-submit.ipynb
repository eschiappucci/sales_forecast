{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "943b2c20",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-26T08:00:40.913504Z",
     "iopub.status.busy": "2024-07-26T08:00:40.913159Z",
     "iopub.status.idle": "2024-07-26T08:01:00.255565Z",
     "shell.execute_reply": "2024-07-26T08:01:00.254755Z"
    },
    "papermill": {
     "duration": 19.349394,
     "end_time": "2024-07-26T08:01:00.257802",
     "exception": false,
     "start_time": "2024-07-26T08:00:40.908408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 12:01:57.602152: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-31 12:01:57.609476: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-31 12:01:57.675738: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-31 12:01:57.730968: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-31 12:01:57.786548: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-31 12:01:57.801867: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-31 12:01:57.896066: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-31 12:01:58.806231: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import math\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_path = 'og_data/'\n",
    "\n",
    "train = pd.read_csv(os.path.join(data_path, 'train.csv'), parse_dates=['date'])\n",
    "test = pd.read_csv(os.path.join(data_path, 'test.csv'), parse_dates=['date'])\n",
    "\n",
    "# holidays_events = pd.read_csv(os.path.join(data_path, 'holidays_events.csv'), parse_dates=['date'])\n",
    "oil = pd.read_csv(os.path.join(data_path, 'oil.csv'), parse_dates=['date'])\n",
    "stores = pd.read_csv(os.path.join(data_path, 'stores.csv'))\n",
    "transactions = pd.read_csv(os.path.join(data_path, 'transactions.csv'), parse_dates=['date'])\n",
    "submission = pd.read_csv(os.path.join(data_path, 'sample_submission.csv'), index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2756fdd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T08:01:00.266033Z",
     "iopub.status.busy": "2024-07-26T08:01:00.265752Z",
     "iopub.status.idle": "2024-07-26T08:01:03.324404Z",
     "shell.execute_reply": "2024-07-26T08:01:03.323452Z"
    },
    "papermill": {
     "duration": 3.065145,
     "end_time": "2024-07-26T08:01:03.326557",
     "exception": false,
     "start_time": "2024-07-26T08:01:00.261412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 1506.5585637191425\n",
      "P-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv(os.path.join(data_path, 'train.csv'), parse_dates=['date'])\n",
    "\n",
    "data['dayofweek'] = data['date'].dt.dayofweek\n",
    "\n",
    "average_sales = data.groupby('dayofweek')['sales'].mean()\n",
    "\n",
    "average_sales.plot(kind='bar', color='skyblue')\n",
    "plt.title('Average Sales by Day of the Week')\n",
    "plt.xlabel('Day of the Week')\n",
    "plt.ylabel('Average Sales')\n",
    "plt.xticks(range(0, 7), ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'], rotation=0)\n",
    "plt.show()\n",
    "\n",
    "grouped = data.groupby('dayofweek')['sales']\n",
    "\n",
    "sales_data = [group for name, group in grouped]\n",
    "\n",
    "f_stat, p_value = f_oneway(*sales_data)\n",
    "print('F-statistic:', f_stat)\n",
    "print('P-value:', p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2d88fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, x= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63a83075",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_min, date_max = train.date.min(), test.date.max()\n",
    "oil['date'] = pd.to_datetime(oil['date'])\n",
    "new_df = pd.DataFrame()\n",
    "new_df['date'] = pd.date_range(date_min, date_max)\n",
    "new_df = pd.merge(new_df,oil, how=\"outer\", on='date')\n",
    "new_df['dcoilwtico'] = new_df['dcoilwtico'].interpolate(method = \"linear\")\n",
    "oil = new_df\n",
    "\n",
    "oil_prices = np.asarray(oil['dcoilwtico'])\n",
    "nans, x= nan_helper(oil_prices)\n",
    "oil_prices[nans]= np.interp(x(nans), x(~nans), oil_prices[~nans])\n",
    "oil['dcoilwtico'] = oil_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17e1ed22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T08:01:03.350481Z",
     "iopub.status.busy": "2024-07-26T08:01:03.350216Z",
     "iopub.status.idle": "2024-07-26T08:01:05.696014Z",
     "shell.execute_reply": "2024-07-26T08:01:05.695126Z"
    },
    "papermill": {
     "duration": 2.35348,
     "end_time": "2024-07-26T08:01:05.698750",
     "exception": false,
     "start_time": "2024-07-26T08:01:03.345270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of the original train data:\n",
      "(1599, 1782)\n",
      "store_nbr                          1                                       \\\n",
      "family                            0    1    2       3    4        5    6    \n",
      "date       dcoilwtico dayofweek                                             \n",
      "2013-01-01 93.140000  1          0.0  0.0  0.0     0.0  0.0    0.000  0.0   \n",
      "2013-01-02 93.140000  2          2.0  0.0  2.0  1091.0  0.0  470.652  0.0   \n",
      "2013-01-03 92.970000  3          3.0  0.0  0.0   919.0  0.0  310.655  0.0   \n",
      "2013-01-04 93.120000  4          3.0  0.0  3.0   953.0  0.0  198.366  0.0   \n",
      "2013-01-05 93.146667  5          5.0  0.0  3.0  1160.0  0.0  301.057  0.0   \n",
      "\n",
      "store_nbr                                                ...    9           \\\n",
      "family                               7      8        9   ...   23       24   \n",
      "date       dcoilwtico dayofweek                          ...                 \n",
      "2013-01-01 93.140000  1             0.0    0.0    0.000  ...  0.0    0.000   \n",
      "2013-01-02 93.140000  2          1060.0  579.0  164.069  ...  0.0  374.531   \n",
      "2013-01-03 92.970000  3           836.0  453.0  151.582  ...  0.0  400.863   \n",
      "2013-01-04 93.120000  4           827.0  460.0  131.411  ...  0.0  310.878   \n",
      "2013-01-05 93.146667  5           811.0  464.0  118.613  ...  0.0  447.685   \n",
      "\n",
      "store_nbr                                                                  \\\n",
      "family                              25   26   27       28    29   30   31   \n",
      "date       dcoilwtico dayofweek                                             \n",
      "2013-01-01 93.140000  1            0.0  0.0  0.0    0.000   0.0  0.0  0.0   \n",
      "2013-01-02 93.140000  2          482.0  0.0  0.0  651.292  83.0  0.0  0.0   \n",
      "2013-01-03 92.970000  3          372.0  0.0  0.0  509.496  66.0  0.0  0.0   \n",
      "2013-01-04 93.120000  4          324.0  0.0  0.0  332.672  57.0  0.0  0.0   \n",
      "2013-01-05 93.146667  5          461.0  0.0  0.0  510.919  84.0  0.0  0.0   \n",
      "\n",
      "store_nbr                                \n",
      "family                               32  \n",
      "date       dcoilwtico dayofweek          \n",
      "2013-01-01 93.140000  1           0.000  \n",
      "2013-01-02 93.140000  2          29.214  \n",
      "2013-01-03 92.970000  3          25.000  \n",
      "2013-01-04 93.120000  4          11.000  \n",
      "2013-01-05 93.146667  5          28.361  \n",
      "\n",
      "[5 rows x 1782 columns]\n",
      "\n",
      "First 5 rows of the original train data:\n",
      "(1599, 1782)\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.11111111 0.         0.16666667 ... 0.         0.         0.48512928]\n",
      " [0.16666667 0.         0.         ... 0.         0.         0.41515136]\n",
      " ...\n",
      " [0.22222222 0.         0.25       ... 0.49480247 0.00920245 0.45467379]\n",
      " [0.05555556 0.         0.08333333 ... 0.59724127 0.02147239 0.65942643]\n",
      " [0.11111111 0.         0.41666667 ... 0.34804615 0.00613497 0.31712582]]\n"
     ]
    }
   ],
   "source": [
    "train_data = train.copy().drop(['onpromotion'], axis=1)\n",
    "test_data = test.copy().drop(['onpromotion'], axis=1)\n",
    "\n",
    "train_data['dayofweek'] = data['date'].dt.dayofweek\n",
    "test_data['dayofweek'] = data['date'].dt.dayofweek\n",
    "\n",
    "train_data = train_data.merge(oil, on='date', how='left')\n",
    "test_data = test_data.merge(oil, on='date', how='left')\n",
    "\n",
    "\n",
    "\n",
    "# Ordinal Encoding for 'family' column\n",
    "ordinal_encoder = OrdinalEncoder(dtype=int)\n",
    "train_data[['family']] = ordinal_encoder.fit_transform(train_data[['family']])\n",
    "test_data[['family']] = ordinal_encoder.transform(test_data[['family']])\n",
    "\n",
    "num_days_train = train[\"date\"].nunique()\n",
    "num_stores_train = train[\"store_nbr\"].nunique()\n",
    "num_families_train = train[\"family\"].nunique()\n",
    "\n",
    "num_days_test = test[\"date\"].nunique()\n",
    "num_stores_test = test[\"store_nbr\"].nunique()\n",
    "num_families_test = test[\"family\"].nunique()\n",
    "\n",
    "pivoted_train = train_data.pivot(index=['date','dcoilwtico','dayofweek'], columns=['store_nbr', 'family'], values='sales')\n",
    "\n",
    "train_samples = int(num_days_train * 0.95)\n",
    "train_samples_df = pivoted_train[:train_samples]\n",
    "valid_samples_df = pivoted_train[train_samples:]\n",
    "\n",
    "print(\"\\nFirst 5 rows of the original train data:\")\n",
    "print(train_samples_df.shape)\n",
    "print(train_samples_df.head())\n",
    "\n",
    "minmax_scaler = MinMaxScaler()\n",
    "minmax_scaler.fit(train_samples_df)\n",
    "scaled_train_samples = minmax_scaler.transform(train_samples_df)\n",
    "scaled_validation_samples = minmax_scaler.transform(valid_samples_df)\n",
    "\n",
    "print(\"\\nFirst 5 rows of the original train data:\")\n",
    "print(scaled_train_samples.shape)\n",
    "print(scaled_train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fccd28a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, count, max_var = 0, 0, 20\n",
    "def get_lr_callback(batch_size=8, mode='cos', epochs=10, plot=False):\n",
    "    lr_start, lr_max, lr_min = 1e-2, 1e-5 * batch_size, 1e-4\n",
    "    lr_ramp_ep, lr_sus_ep, lr_decay = 0, 0, 0.75\n",
    "    line_max, line_min = 1, 1e-2\n",
    "    \n",
    "    def lrfn(epoch):  # Learning rate update function\n",
    "        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n",
    "        elif mode == 'exp': lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "        elif mode == 'line': \n",
    "            m = (lr_min - lr_start)/epochs\n",
    "            lr = m * epoch + lr_start\n",
    "        elif mode == 'step': lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n",
    "        elif mode == 'cos':\n",
    "            decay_total_epochs, decay_epoch_index = (epochs - lr_ramp_ep - lr_sus_ep) /(epochs/20), epoch - lr_ramp_ep - lr_sus_ep\n",
    "            phase = math.pi * decay_epoch_index / decay_total_epochs\n",
    "            m = (line_min - line_max)/epochs\n",
    "            control = m * epoch + line_max\n",
    "            lr = ((lr_start - lr_min) * (1+np.cos(phase)) + lr_min) * control\n",
    "        elif mode == 'var':\n",
    "            global a, count, max_var\n",
    "            m = (lr_min - lr_start)/max_var\n",
    "            if a < max_var:\n",
    "                lr = m * (epoch-count) + lr_start\n",
    "                a += 1\n",
    "            elif a >= max_var:\n",
    "                print(epoch-count)\n",
    "                lr = m * (epoch-count) + lr_start\n",
    "                count += max_var + 1\n",
    "                a = 0\n",
    "        return lr\n",
    "\n",
    "    if plot:  # Plot lr curve if plot is True\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n",
    "        plt.xlabel('epoch'); plt.ylabel('lr')\n",
    "        plt.title('LR Scheduler')\n",
    "        plt.show()\n",
    "\n",
    "    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # Create lr callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "149d8112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 512\n",
    "lr_mode = 'line'\n",
    "epochs = 1000 \n",
    "lr_cb = get_lr_callback(batch_size, mode=lr_mode, epochs=epochs, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad32ef96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T08:01:05.709144Z",
     "iopub.status.busy": "2024-07-26T08:01:05.708458Z",
     "iopub.status.idle": "2024-07-26T08:05:05.541386Z",
     "shell.execute_reply": "2024-07-26T08:05:05.540347Z"
    },
    "papermill": {
     "duration": 239.840818,
     "end_time": "2024-07-26T08:05:05.543883",
     "exception": false,
     "start_time": "2024-07-26T08:01:05.703065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,586,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_78          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_12            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">601,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_79          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_13            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_80          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_14            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_81          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_15            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ separable_conv1d_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">317,200</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv1D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_16            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ separable_conv1d_5              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,055,000</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv1D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_17            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ separable_conv1d_6              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,055,000</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv1D</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_18            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_10             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1782</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,783,782</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_78 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │     \u001b[38;5;34m1,586,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_78          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │           \u001b[38;5;34m800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_12            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_79 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │       \u001b[38;5;34m601,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_79          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │         \u001b[38;5;34m1,200\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_13            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_80 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │       \u001b[38;5;34m721,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_80          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │         \u001b[38;5;34m1,200\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_14            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_81 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │       \u001b[38;5;34m721,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_81          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │         \u001b[38;5;34m1,200\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_15            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ separable_conv1d_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1000\u001b[0m)       │       \u001b[38;5;34m317,200\u001b[0m │\n",
       "│ (\u001b[38;5;33mSeparableConv1D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_16            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1000\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ separable_conv1d_5              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1000\u001b[0m)       │     \u001b[38;5;34m1,055,000\u001b[0m │\n",
       "│ (\u001b[38;5;33mSeparableConv1D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_17            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1000\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ separable_conv1d_6              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1000\u001b[0m)       │     \u001b[38;5;34m1,055,000\u001b[0m │\n",
       "│ (\u001b[38;5;33mSeparableConv1D\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_18            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1000\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_10             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1782\u001b[0m)       │     \u001b[38;5;34m1,783,782\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,845,382</span> (29.93 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,845,382\u001b[0m (29.93 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,843,182</span> (29.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,843,182\u001b[0m (29.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,200</span> (8.59 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,200\u001b[0m (8.59 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6s/step - loss: 0.1437 - msle: 0.0342 - val_loss: 0.1220 - val_msle: 0.0178 - learning_rate: 0.0100\n",
      "Epoch 2/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5s/step - loss: 0.1252 - msle: 0.0174 - val_loss: 0.1296 - val_msle: 0.0203 - learning_rate: 0.0100\n",
      "Epoch 3/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6s/step - loss: 0.1491 - msle: 0.0243 - val_loss: 0.1486 - val_msle: 0.0276 - learning_rate: 0.0100\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 13:50:11.552324: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 310210560 bytes after encountering the first element of size 310210560 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.4305 - msle: 0.0950 - val_loss: 0.4148 - val_msle: 0.0730 - learning_rate: 0.0100\n",
      "Epoch 5/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6s/step - loss: 0.7015 - msle: 0.1441 - val_loss: 0.2398 - val_msle: 0.0410 - learning_rate: 0.0100\n",
      "Epoch 6/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6s/step - loss: 1.1409 - msle: 0.2653 - val_loss: 3.2972 - val_msle: 0.7268 - learning_rate: 0.0100\n",
      "Epoch 7/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6s/step - loss: 2.9169 - msle: 0.8017 - val_loss: 0.6440 - val_msle: 0.0878 - learning_rate: 0.0099\n",
      "Epoch 8/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5s/step - loss: 1.8949 - msle: 0.4486 - val_loss: 3.6827 - val_msle: 1.1076 - learning_rate: 0.0099\n",
      "Epoch 9/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5s/step - loss: 18.5777 - msle: 3.3864 - val_loss: 4.4548 - val_msle: 0.9740 - learning_rate: 0.0099\n",
      "Epoch 10/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5s/step - loss: 5.1475 - msle: 1.2494 - val_loss: 23.9691 - val_msle: 4.7453 - learning_rate: 0.0099\n",
      "Epoch 11/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 23.8421 - msle: 4.3615 - val_loss: 7.4661 - val_msle: 1.7186 - learning_rate: 0.0099\n",
      "Epoch 12/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 4.2602 - msle: 1.0817 - val_loss: 2.5399 - val_msle: 0.6059 - learning_rate: 0.0099\n",
      "Epoch 13/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 3.8548 - msle: 1.0559 - val_loss: 1.2016 - val_msle: 0.2705 - learning_rate: 0.0099\n",
      "Epoch 14/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 1.2225 - msle: 0.3012 - val_loss: 2.7110 - val_msle: 0.6180 - learning_rate: 0.0099\n",
      "Epoch 15/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 1.4209 - msle: 0.3512 - val_loss: 2.9665 - val_msle: 0.8055 - learning_rate: 0.0099\n",
      "Epoch 16/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 1.4462 - msle: 0.3762 - val_loss: 1.7097 - val_msle: 0.4168 - learning_rate: 0.0099\n",
      "Epoch 17/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5s/step - loss: 0.7093 - msle: 0.1566 - val_loss: 1.5156 - val_msle: 0.3119 - learning_rate: 0.0098\n",
      "Epoch 18/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.6610 - msle: 0.1438 - val_loss: 3.7524 - val_msle: 0.9120 - learning_rate: 0.0098\n",
      "Epoch 19/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.5430 - msle: 0.1092 - val_loss: 1.2083 - val_msle: 0.3226 - learning_rate: 0.0098\n",
      "Epoch 20/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.4331 - msle: 0.0879 - val_loss: 1.7679 - val_msle: 0.5366 - learning_rate: 0.0098\n",
      "Epoch 21/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.2718 - msle: 0.0469 - val_loss: 2.0536 - val_msle: 0.6456 - learning_rate: 0.0098\n",
      "Epoch 22/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5s/step - loss: 0.2303 - msle: 0.0386 - val_loss: 1.6121 - val_msle: 0.5249 - learning_rate: 0.0098\n",
      "Epoch 23/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5s/step - loss: 0.1836 - msle: 0.0277 - val_loss: 1.3730 - val_msle: 0.4298 - learning_rate: 0.0098\n",
      "Epoch 24/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5s/step - loss: 0.1675 - msle: 0.0251 - val_loss: 0.6019 - val_msle: 0.1501 - learning_rate: 0.0098\n",
      "Epoch 25/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.1474 - msle: 0.0201 - val_loss: 0.7304 - val_msle: 0.1560 - learning_rate: 0.0098\n",
      "Epoch 26/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.1374 - msle: 0.0181 - val_loss: 0.3627 - val_msle: 0.0594 - learning_rate: 0.0098\n",
      "Epoch 27/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.1323 - msle: 0.0169 - val_loss: 0.3702 - val_msle: 0.0566 - learning_rate: 0.0097\n",
      "Epoch 28/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5s/step - loss: 0.1161 - msle: 0.0146 - val_loss: 0.3404 - val_msle: 0.0522 - learning_rate: 0.0097\n",
      "Epoch 29/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.1101 - msle: 0.0134 - val_loss: 0.2822 - val_msle: 0.0448 - learning_rate: 0.0097\n",
      "Epoch 30/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0999 - msle: 0.0120 - val_loss: 0.2596 - val_msle: 0.0376 - learning_rate: 0.0097\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 13:57:46.814586: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 310210560 bytes after encountering the first element of size 310210560 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.0958 - msle: 0.0115 - val_loss: 0.2225 - val_msle: 0.0322 - learning_rate: 0.0097\n",
      "Epoch 32/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5s/step - loss: 0.0928 - msle: 0.0110 - val_loss: 0.2270 - val_msle: 0.0341 - learning_rate: 0.0097\n",
      "Epoch 33/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.0906 - msle: 0.0109 - val_loss: 0.2618 - val_msle: 0.0378 - learning_rate: 0.0097\n",
      "Epoch 34/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0903 - msle: 0.0108 - val_loss: 0.1795 - val_msle: 0.0284 - learning_rate: 0.0097\n",
      "Epoch 35/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0878 - msle: 0.0106 - val_loss: 0.1587 - val_msle: 0.0264 - learning_rate: 0.0097\n",
      "Epoch 36/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5s/step - loss: 0.0877 - msle: 0.0107 - val_loss: 0.1677 - val_msle: 0.0270 - learning_rate: 0.0097\n",
      "Epoch 37/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5s/step - loss: 0.0860 - msle: 0.0105 - val_loss: 0.1870 - val_msle: 0.0286 - learning_rate: 0.0096\n",
      "Epoch 38/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.0856 - msle: 0.0106 - val_loss: 0.1693 - val_msle: 0.0266 - learning_rate: 0.0096\n",
      "Epoch 39/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0852 - msle: 0.0105 - val_loss: 0.1454 - val_msle: 0.0247 - learning_rate: 0.0096\n",
      "Epoch 40/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7s/step - loss: 0.0848 - msle: 0.0106 - val_loss: 0.1545 - val_msle: 0.0250 - learning_rate: 0.0096\n",
      "Epoch 41/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6s/step - loss: 0.0849 - msle: 0.0106 - val_loss: 0.1574 - val_msle: 0.0251 - learning_rate: 0.0096\n",
      "Epoch 42/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.0843 - msle: 0.0106 - val_loss: 0.1577 - val_msle: 0.0250 - learning_rate: 0.0096\n",
      "Epoch 43/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0842 - msle: 0.0106 - val_loss: 0.1426 - val_msle: 0.0239 - learning_rate: 0.0096\n",
      "Epoch 44/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0841 - msle: 0.0106 - val_loss: 0.1380 - val_msle: 0.0236 - learning_rate: 0.0096\n",
      "Epoch 45/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0836 - msle: 0.0105 - val_loss: 0.1437 - val_msle: 0.0238 - learning_rate: 0.0096\n",
      "Epoch 46/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0836 - msle: 0.0105 - val_loss: 0.1417 - val_msle: 0.0235 - learning_rate: 0.0096\n",
      "Epoch 47/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0832 - msle: 0.0105 - val_loss: 0.1348 - val_msle: 0.0231 - learning_rate: 0.0095\n",
      "Epoch 48/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0830 - msle: 0.0105 - val_loss: 0.1345 - val_msle: 0.0231 - learning_rate: 0.0095\n",
      "Epoch 49/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.0830 - msle: 0.0105 - val_loss: 0.1321 - val_msle: 0.0229 - learning_rate: 0.0095\n",
      "Epoch 50/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.0828 - msle: 0.0105 - val_loss: 0.1286 - val_msle: 0.0227 - learning_rate: 0.0095\n",
      "Epoch 51/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0828 - msle: 0.0105 - val_loss: 0.1263 - val_msle: 0.0227 - learning_rate: 0.0095\n",
      "Epoch 52/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0827 - msle: 0.0105 - val_loss: 0.1275 - val_msle: 0.0226 - learning_rate: 0.0095\n",
      "Epoch 53/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.0827 - msle: 0.0105 - val_loss: 0.1280 - val_msle: 0.0226 - learning_rate: 0.0095\n",
      "Epoch 54/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.0826 - msle: 0.0105 - val_loss: 0.1248 - val_msle: 0.0225 - learning_rate: 0.0095\n",
      "Epoch 55/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0823 - msle: 0.0104 - val_loss: 0.1245 - val_msle: 0.0224 - learning_rate: 0.0095\n",
      "Epoch 56/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0824 - msle: 0.0105 - val_loss: 0.1242 - val_msle: 0.0223 - learning_rate: 0.0095\n",
      "Epoch 57/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0824 - msle: 0.0105 - val_loss: 0.1234 - val_msle: 0.0223 - learning_rate: 0.0094\n",
      "Epoch 58/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.0823 - msle: 0.0105 - val_loss: 0.1244 - val_msle: 0.0223 - learning_rate: 0.0094\n",
      "Epoch 59/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0820 - msle: 0.0104 - val_loss: 0.1264 - val_msle: 0.0223 - learning_rate: 0.0094\n",
      "Epoch 60/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.0821 - msle: 0.0104 - val_loss: 0.1230 - val_msle: 0.0222 - learning_rate: 0.0094\n",
      "Epoch 61/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5s/step - loss: 0.0820 - msle: 0.0104 - val_loss: 0.1219 - val_msle: 0.0222 - learning_rate: 0.0094\n",
      "Epoch 62/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.0819 - msle: 0.0104 - val_loss: 0.1230 - val_msle: 0.0221 - learning_rate: 0.0094\n",
      "Epoch 63/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.0817 - msle: 0.0104 - val_loss: 0.1238 - val_msle: 0.0220 - learning_rate: 0.0094\n",
      "Epoch 64/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0819 - msle: 0.0104 - val_loss: 0.1200 - val_msle: 0.0219 - learning_rate: 0.0094\n",
      "Epoch 65/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0817 - msle: 0.0104 - val_loss: 0.1191 - val_msle: 0.0219 - learning_rate: 0.0094\n",
      "Epoch 66/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.0814 - msle: 0.0104 - val_loss: 0.1197 - val_msle: 0.0218 - learning_rate: 0.0094\n",
      "Epoch 67/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.0816 - msle: 0.0104 - val_loss: 0.1209 - val_msle: 0.0217 - learning_rate: 0.0093\n",
      "Epoch 68/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.0816 - msle: 0.0104 - val_loss: 0.1185 - val_msle: 0.0217 - learning_rate: 0.0093\n",
      "Epoch 69/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.0814 - msle: 0.0104 - val_loss: 0.1182 - val_msle: 0.0217 - learning_rate: 0.0093\n",
      "Epoch 70/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0814 - msle: 0.0104 - val_loss: 0.1199 - val_msle: 0.0215 - learning_rate: 0.0093\n",
      "Epoch 71/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0814 - msle: 0.0104 - val_loss: 0.1186 - val_msle: 0.0215 - learning_rate: 0.0093\n",
      "Epoch 72/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0813 - msle: 0.0104 - val_loss: 0.1169 - val_msle: 0.0216 - learning_rate: 0.0093\n",
      "Epoch 73/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0812 - msle: 0.0104 - val_loss: 0.1174 - val_msle: 0.0215 - learning_rate: 0.0093\n",
      "Epoch 74/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0811 - msle: 0.0104 - val_loss: 0.1185 - val_msle: 0.0214 - learning_rate: 0.0093\n",
      "Epoch 75/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0811 - msle: 0.0104 - val_loss: 0.1177 - val_msle: 0.0214 - learning_rate: 0.0093\n",
      "Epoch 76/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0811 - msle: 0.0104 - val_loss: 0.1166 - val_msle: 0.0215 - learning_rate: 0.0093\n",
      "Epoch 77/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0811 - msle: 0.0104 - val_loss: 0.1163 - val_msle: 0.0214 - learning_rate: 0.0092\n",
      "Epoch 78/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0809 - msle: 0.0104 - val_loss: 0.1172 - val_msle: 0.0213 - learning_rate: 0.0092\n",
      "Epoch 79/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0810 - msle: 0.0104 - val_loss: 0.1157 - val_msle: 0.0214 - learning_rate: 0.0092\n",
      "Epoch 80/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0810 - msle: 0.0104 - val_loss: 0.1153 - val_msle: 0.0214 - learning_rate: 0.0092\n",
      "Epoch 81/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0808 - msle: 0.0104 - val_loss: 0.1151 - val_msle: 0.0213 - learning_rate: 0.0092\n",
      "Epoch 82/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0807 - msle: 0.0104 - val_loss: 0.1155 - val_msle: 0.0213 - learning_rate: 0.0092\n",
      "Epoch 83/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0808 - msle: 0.0104 - val_loss: 0.1156 - val_msle: 0.0212 - learning_rate: 0.0092\n",
      "Epoch 84/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0809 - msle: 0.0104 - val_loss: 0.1152 - val_msle: 0.0212 - learning_rate: 0.0092\n",
      "Epoch 85/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0807 - msle: 0.0104 - val_loss: 0.1148 - val_msle: 0.0212 - learning_rate: 0.0092\n",
      "Epoch 86/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.0806 - msle: 0.0104 - val_loss: 0.1147 - val_msle: 0.0212 - learning_rate: 0.0092\n",
      "Epoch 87/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.0806 - msle: 0.0104 - val_loss: 0.1143 - val_msle: 0.0212 - learning_rate: 0.0091\n",
      "Epoch 88/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.0807 - msle: 0.0104 - val_loss: 0.1141 - val_msle: 0.0212 - learning_rate: 0.0091\n",
      "Epoch 89/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - loss: 0.0806 - msle: 0.0104 - val_loss: 0.1140 - val_msle: 0.0211 - learning_rate: 0.0091\n",
      "Epoch 90/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0805 - msle: 0.0104 - val_loss: 0.1139 - val_msle: 0.0211 - learning_rate: 0.0091\n",
      "Epoch 91/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0806 - msle: 0.0104 - val_loss: 0.1141 - val_msle: 0.0210 - learning_rate: 0.0091\n",
      "Epoch 92/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0807 - msle: 0.0104 - val_loss: 0.1134 - val_msle: 0.0211 - learning_rate: 0.0091\n",
      "Epoch 93/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0807 - msle: 0.0104 - val_loss: 0.1133 - val_msle: 0.0210 - learning_rate: 0.0091\n",
      "Epoch 94/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0804 - msle: 0.0104 - val_loss: 0.1133 - val_msle: 0.0210 - learning_rate: 0.0091\n",
      "Epoch 95/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0804 - msle: 0.0104 - val_loss: 0.1131 - val_msle: 0.0209 - learning_rate: 0.0091\n",
      "Epoch 96/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0805 - msle: 0.0104 - val_loss: 0.1127 - val_msle: 0.0209 - learning_rate: 0.0091\n",
      "Epoch 97/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0803 - msle: 0.0104 - val_loss: 0.1124 - val_msle: 0.0209 - learning_rate: 0.0090\n",
      "Epoch 98/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0802 - msle: 0.0104 - val_loss: 0.1123 - val_msle: 0.0209 - learning_rate: 0.0090\n",
      "Epoch 99/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0802 - msle: 0.0104 - val_loss: 0.1124 - val_msle: 0.0208 - learning_rate: 0.0090\n",
      "Epoch 100/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0803 - msle: 0.0104 - val_loss: 0.1124 - val_msle: 0.0208 - learning_rate: 0.0090\n",
      "Epoch 101/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6s/step - loss: 0.0804 - msle: 0.0104 - val_loss: 0.1120 - val_msle: 0.0208 - learning_rate: 0.0090\n"
     ]
    }
   ],
   "source": [
    "def split_series(series, n_past, n_future):\n",
    "    X, y = [], []\n",
    "    for window_start in range(len(series)):\n",
    "        past_end = window_start + n_past\n",
    "        future_end = past_end + n_future\n",
    "        if future_end > len(series):\n",
    "            break\n",
    "        X.append(series[window_start:past_end, :])\n",
    "        y.append(series[past_end:future_end, :])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "n_future = 16\n",
    "n_past = scaled_validation_samples.shape[0] - n_future\n",
    "n_features = num_stores_train * num_families_train\n",
    "\n",
    "X_train, y_train = split_series(scaled_train_samples, n_past, n_future)\n",
    "X_val, y_val = split_series(scaled_validation_samples, n_past, n_future)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.LSTM(units=200, return_sequences=True, input_shape=(n_past, n_features)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.SpatialDropout1D(0.2))\n",
    "model.add(layers.LSTM(units=300, return_sequences=True))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.SpatialDropout1D(0.2))\n",
    "model.add(layers.LSTM(units=300, return_sequences=True))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.SpatialDropout1D(0.2))\n",
    "model.add(layers.LSTM(units=300, return_sequences=True))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.SpatialDropout1D(0.2))\n",
    "model.add(layers.SeparableConv1D(filters=1000, kernel_size=(n_past - n_future + 1)))\n",
    "model.add(layers.SpatialDropout1D(0.2))\n",
    "model.add(layers.SeparableConv1D(filters=1000, kernel_size=(n_past - n_future + 1), padding='same'))\n",
    "model.add(layers.SpatialDropout1D(0.2))\n",
    "model.add(layers.SeparableConv1D(filters=1000, kernel_size=(n_past - n_future + 1), padding='same'))\n",
    "model.add(layers.SpatialDropout1D(0.2))\n",
    "model.add(layers.TimeDistributed(layers.Dense(n_features)))\n",
    "\n",
    "model.compile(loss='mae', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['msle'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_msle', min_delta=1e-5, patience=100, restore_best_weights=True)\n",
    "\n",
    "model_history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, callbacks=[lr_cb, early_stopping], \n",
    "                          batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "490023ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T08:05:06.218684Z",
     "iopub.status.busy": "2024-07-26T08:05:06.218326Z",
     "iopub.status.idle": "2024-07-26T08:05:06.795815Z",
     "shell.execute_reply": "2024-07-26T08:05:06.794869Z"
    },
    "papermill": {
     "duration": 0.748359,
     "end_time": "2024-07-26T08:05:06.797773",
     "exception": false,
     "start_time": "2024-07-26T08:05:06.049414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b3b3f011990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627ms/step\n"
     ]
    }
   ],
   "source": [
    "x_test_pred = scaled_validation_samples[-n_past:].reshape((1, n_past, n_features))\n",
    "scaled_y_predict = model.predict(x_test_pred)\n",
    "\n",
    "y_predict = pd.DataFrame(minmax_scaler.inverse_transform(scaled_y_predict.reshape((n_future, n_features))), columns=valid_samples_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "effd2ca0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T08:05:07.139459Z",
     "iopub.status.busy": "2024-07-26T08:05:07.138630Z",
     "iopub.status.idle": "2024-07-26T08:05:20.854097Z",
     "shell.execute_reply": "2024-07-26T08:05:20.852995Z"
    },
    "papermill": {
     "duration": 13.887426,
     "end_time": "2024-07-26T08:05:20.856161",
     "exception": false,
     "start_time": "2024-07-26T08:05:06.968735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of the data:\n",
      "               sales\n",
      "id                  \n",
      "3000888     5.119675\n",
      "3000889     0.026587\n",
      "3000890     3.812581\n",
      "3000891  1688.847412\n",
      "3000892     0.516341\n"
     ]
    }
   ],
   "source": [
    "pivoted_test = test_data.pivot(index=['date','dcoilwtico','dayofweek'], columns=['store_nbr', 'family'], values='id')\n",
    "\n",
    "for day_ith, day_ith_pred in y_predict.iterrows():\n",
    "    for n_samples_per_day in range(len(day_ith_pred)):\n",
    "        sample_id = pivoted_test.iloc[[day_ith], [n_samples_per_day]].values[0][0]\n",
    "        values = max(0, day_ith_pred.values[n_samples_per_day])\n",
    "        submission.at[sample_id, 'sales'] = max(0, day_ith_pred.values[n_samples_per_day])\n",
    "\n",
    "submission.to_csv('submission.csv')\n",
    "print(\"\\nFirst 5 rows of the data:\")\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 2887556,
     "sourceId": 29781,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 286.363123,
   "end_time": "2024-07-26T08:05:24.383801",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-26T08:00:38.020678",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
